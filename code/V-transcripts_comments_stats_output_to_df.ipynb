{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.symbols import amod\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import scattertext as st\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "\n",
    "\n",
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import swat\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ted_video_transcripts_2416.pkl', 'rb') as picklefile:\n",
    "    talks = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ted_video_stats_2722.pkl', 'rb') as picklefile:\n",
    "    stats = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/elena/Desktop/Metis/Project_4_Ted/Project-4-Ted\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ted_video_comments_emotions.pkl', 'rb') as picklefile:\n",
    "    comment = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>YgAuFqEs6yk</td>\n",
       "      <td>[{'text': 'I remember watching my father raise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bNmRr-BYnxA</td>\n",
       "      <td>[{'text': 'Transcriber: Joseph Geni\n",
       "Reviewer: ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                         transcript\n",
       "0  YgAuFqEs6yk  [{'text': 'I remember watching my father raise...\n",
       "1  bNmRr-BYnxA  [{'text': 'Transcriber: Joseph Geni\n",
       "Reviewer: ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talks.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2416"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(talks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>publushed_date</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>dislike_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>views_count</th>\n",
       "      <th>today</th>\n",
       "      <th>days_age</th>\n",
       "      <th>views_per_day</th>\n",
       "      <th>dislike_perc_of_likes</th>\n",
       "      <th>success</th>\n",
       "      <th>prime_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Bb7kz1THJPU</td>\n",
       "      <td>[Science Fiction, Future, Creativity, Society,...</td>\n",
       "      <td>Go ahead, dream about the future | Charlie Jan...</td>\n",
       "      <td>2020-04-20 13:28:47</td>\n",
       "      <td>653</td>\n",
       "      <td>846</td>\n",
       "      <td>2082</td>\n",
       "      <td>71384</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>25</td>\n",
       "      <td>2855.360000</td>\n",
       "      <td>40.634006</td>\n",
       "      <td>no</td>\n",
       "      <td>Science Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cTIUiN6inIQ</td>\n",
       "      <td>[The Way We Work, work]</td>\n",
       "      <td>How to make faster decisions | The Way We Work...</td>\n",
       "      <td>2020-02-10 15:00:24</td>\n",
       "      <td>98</td>\n",
       "      <td>84</td>\n",
       "      <td>4298</td>\n",
       "      <td>145314</td>\n",
       "      <td>2020-05-16</td>\n",
       "      <td>95</td>\n",
       "      <td>1529.621053</td>\n",
       "      <td>1.954397</td>\n",
       "      <td>yes</td>\n",
       "      <td>The Way We Work</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                               tags  \\\n",
       "0  Bb7kz1THJPU  [Science Fiction, Future, Creativity, Society,...   \n",
       "0  cTIUiN6inIQ                            [The Way We Work, work]   \n",
       "\n",
       "                                               title      publushed_date  \\\n",
       "0  Go ahead, dream about the future | Charlie Jan... 2020-04-20 13:28:47   \n",
       "0  How to make faster decisions | The Way We Work... 2020-02-10 15:00:24   \n",
       "\n",
       "  comments_count dislike_count like_count views_count      today  days_age  \\\n",
       "0            653           846       2082       71384 2020-05-16        25   \n",
       "0             98            84       4298      145314 2020-05-16        95   \n",
       "\n",
       "   views_per_day  dislike_perc_of_likes success        prime_tag  \n",
       "0    2855.360000              40.634006      no  Science Fiction  \n",
       "0    1529.621053               1.954397     yes  The Way We Work  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2722"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcript(dirty_line):\n",
    "    output = ''\n",
    "    for el in dirty_line: #df['transcript'].values[0]\n",
    "        for key, value in el.items():\n",
    "            line_output = str.join(\"\", value)\n",
    "            output += \" \" \n",
    "            output += line_output\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "talks['transcript'] = talks['transcript'].map(clean_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words_list = ['Transcriber', 'Translator', 'reviewer', 'thanks', 'thank', '\\n',\n",
    "                     'applause','music', 'Laughter', 'applaud', 'TED', 'applause', 'TED Talks',\n",
    "                     'TED workshop', 'Elizabeth',  'Gilbert', 'Ivana', 'Korom','Krystian', 'Aparta', 'Walters',\n",
    "                     'Joseph','Geni', 'thing', 'think', 'know', 'like', 'way', 'look', 'lot', 'good', 'bad', 'want', 'kind', \n",
    "                     'talk', 'word', 'actually', 'hi', 'woman', 'man', \n",
    "                      'people', 'say', 'come', 'feel', 'tell','ve', 'day', 'right','think',\n",
    "                     '']\n",
    "for word in my_stop_words_list:\n",
    "    spacy.lang.en.stop_words.STOP_WORDS.add(word)\n",
    "    nlp.vocab[word].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = []\n",
    "for i in range(talks.shape[0]):\n",
    "    persons.append([ent.text for ent in nlp(talks['transcript'][i]).ents if ent.label_ == 'PERSON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_flat_list = [item for sublist in persons for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#persons_flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_flat_list = str(persons_flat_list).replace(\"'\", '').replace(\",\", '').replace(\":\", '').replace(\"[\", '').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = ['Parenthood', 'Mamas', 'corona','misstep', 'monk', 'moon', 'Paris', 'attach kid', 'Berlin 2005', \n",
    "          'butterfly', 'Xbox', 'Uber Lyft', 'Crisis Text Line', 'God', 'Law', 'Moon', 'Sun', 'microphone hiss',\n",
    "          'sanitary napkin', 'hygiene piece', 'hygiene piece', 'downright macabre','berlin',\n",
    "          'applaud african', 'diaspora hear', 'politician mirror', 'bradfeld', 'carrier asymptomatic',\n",
    "          'New Yorker', 'yank mouth', 'metaphor monk', 'Facebook', 'LEGOs lego', 'lot hubris','healthy leafy green',\n",
    "          'hygiene factor', 'healthy melatonin', 'lover gentle', 'mosquito','Gmail','iCloud Apple',\n",
    "          'Kaspersky', 'bomb satsang wood', 'kiosk', 'intro', 'sama buona ICU', 'need belong','thousand',\n",
    "          'snooze button', 'primarily white', 'gnash throat', 'fangirl learn', 'Xbox PlayStation', 'butterfly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "persons_flat_list = persons_flat_list\n",
    "for i in persons_flat_list:\n",
    "    if i in errors:\n",
    "       # print(i)\n",
    "        persons_flat_list.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#persons_flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in persons_flat_list:\n",
    "    spacy.lang.en.stop_words.STOP_WORDS.add(word)\n",
    "    nlp.vocab[word].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['woman'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########talks = talks.iloc[:50, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>YgAuFqEs6yk</td>\n",
       "      <td>I remember watching my father raised the pist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bNmRr-BYnxA</td>\n",
       "      <td>Transcriber: Joseph Geni\\nReviewer: Camille M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FVUkKKc3Vvk</td>\n",
       "      <td>Hi, everyone, my name is Elizabeth, and I wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8bj0GR34XWc</td>\n",
       "      <td>Transcriber: Ivana Korom\\nReviewer: Krystian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>eaCrsBtiYA4</td>\n",
       "      <td>I am a public policy wonk. I investigate data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>OMDVTZ-ycaY</td>\n",
       "      <td>Transcriber: Joseph Geni\\nReviewer: Joanna Pi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                         transcript\n",
       "0  YgAuFqEs6yk   I remember watching my father raised the pist...\n",
       "1  bNmRr-BYnxA   Transcriber: Joseph Geni\\nReviewer: Camille M...\n",
       "2  FVUkKKc3Vvk   Hi, everyone, my name is Elizabeth, and I wor...\n",
       "3  8bj0GR34XWc   Transcriber: Ivana Korom\\nReviewer: Krystian ...\n",
       "4  eaCrsBtiYA4   I am a public policy wonk. I investigate data...\n",
       "5  OMDVTZ-ycaY   Transcriber: Joseph Geni\\nReviewer: Joanna Pi..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talks.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "talks['transcript1'] = talks.transcript.apply(\n",
    "    lambda text: ' '.join(token.orth_ for token in nlp(text) if not token.is_punct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "talks['transcript2'] = talks.transcript1.apply(\n",
    "    lambda text: ' '.join(token.lemma_ for token in nlp(text) if not token.is_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "talks['transcript2'] = talks['transcript2'].apply(lambda text: re.sub('\\n', '', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "talks['transcript'] = talks['transcript2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "talks.drop(['transcript1', 'transcript2'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "talks['transcript'] = talks['transcript'].apply(lambda text: re.sub(r'\\b[0-9]+\\b\\W*', '', text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plarity scores addition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "def extract_polarity(text, polarity_type = 'neg'):\n",
    "    all_val = analyser.polarity_scores(text)\n",
    "    return all_val[polarity_type]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "talks['polarity_neg_transcript'] = talks['transcript'].map(extract_polarity)\n",
    "talks['polarity_pos_transcript'] = talks['transcript'].apply(extract_polarity, polarity_type = 'pos')\n",
    "talks['polarity_neu_transcript'] = talks['transcript'].apply(extract_polarity, polarity_type = 'neu')\n",
    "talks['polarity_compound_transcript'] = talks['transcript'].apply(extract_polarity, polarity_type = 'compound')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(talks, stats,  how='left', left_on='video_id', right_on = 'video_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>polarity_neg_transcript</th>\n",
       "      <th>polarity_pos_transcript</th>\n",
       "      <th>polarity_neu_transcript</th>\n",
       "      <th>polarity_compound_transcript</th>\n",
       "      <th>tags</th>\n",
       "      <th>title</th>\n",
       "      <th>publushed_date</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>...</th>\n",
       "      <th>trust</th>\n",
       "      <th>fear</th>\n",
       "      <th>negative</th>\n",
       "      <th>sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>surprise</th>\n",
       "      <th>positive</th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "      <th>anticipation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>YgAuFqEs6yk</td>\n",
       "      <td>remember watch father raise pistol plead gu...</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>[Family, Parenting, Communication, Children, R...</td>\n",
       "      <td>How to co-parent as allies, not adversaries | ...</td>\n",
       "      <td>2020-05-14 14:40:00</td>\n",
       "      <td>109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>0.008664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>bNmRr-BYnxA</td>\n",
       "      <td>think give   half humanity ' spend   week...</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>[climate change, environment, global issues, c...</td>\n",
       "      <td>How to shift your mindset and choose your futu...</td>\n",
       "      <td>2020-05-13 14:22:51</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008208</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.021888</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.008664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>FVUkKKc3Vvk</td>\n",
       "      <td>work trading floor ' m pretty new graduate ...</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>[Life, Society, Immigration, Humanity, Self, P...</td>\n",
       "      <td>What's missing from the American immigrant nar...</td>\n",
       "      <td>2020-05-12 18:06:31</td>\n",
       "      <td>234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.005016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8bj0GR34XWc</td>\n",
       "      <td>worry pandemic pretty life play absolut...</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>[global issues, science, collaboration, virus,...</td>\n",
       "      <td>A global pandemic calls for global solutions |...</td>\n",
       "      <td>2020-05-11 15:52:37</td>\n",
       "      <td>236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.002280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>eaCrsBtiYA4</td>\n",
       "      <td>public policy wonk investigate datum point ...</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.636</td>\n",
       "      <td>-0.9904</td>\n",
       "      <td>[]</td>\n",
       "      <td>Racism has a cost for everyone | Heather C. Mc...</td>\n",
       "      <td>2020-05-08 18:44:35</td>\n",
       "      <td>542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.008208</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.003192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                         transcript  \\\n",
       "0  YgAuFqEs6yk     remember watch father raise pistol plead gu...   \n",
       "1  bNmRr-BYnxA       think give   half humanity ' spend   week...   \n",
       "2  FVUkKKc3Vvk     work trading floor ' m pretty new graduate ...   \n",
       "3  8bj0GR34XWc         worry pandemic pretty life play absolut...   \n",
       "4  eaCrsBtiYA4     public policy wonk investigate datum point ...   \n",
       "\n",
       "   polarity_neg_transcript  polarity_pos_transcript  polarity_neu_transcript  \\\n",
       "0                    0.133                    0.330                    0.537   \n",
       "1                    0.194                    0.267                    0.539   \n",
       "2                    0.111                    0.306                    0.583   \n",
       "3                    0.135                    0.166                    0.699   \n",
       "4                    0.200                    0.164                    0.636   \n",
       "\n",
       "   polarity_compound_transcript  \\\n",
       "0                        0.9996   \n",
       "1                        0.9980   \n",
       "2                        0.9993   \n",
       "3                        0.9492   \n",
       "4                       -0.9904   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [Family, Parenting, Communication, Children, R...   \n",
       "1  [climate change, environment, global issues, c...   \n",
       "2  [Life, Society, Immigration, Humanity, Self, P...   \n",
       "3  [global issues, science, collaboration, virus,...   \n",
       "4                                                 []   \n",
       "\n",
       "                                               title      publushed_date  \\\n",
       "0  How to co-parent as allies, not adversaries | ... 2020-05-14 14:40:00   \n",
       "1  How to shift your mindset and choose your futu... 2020-05-13 14:22:51   \n",
       "2  What's missing from the American immigrant nar... 2020-05-12 18:06:31   \n",
       "3  A global pandemic calls for global solutions |... 2020-05-11 15:52:37   \n",
       "4  Racism has a cost for everyone | Heather C. Mc... 2020-05-08 18:44:35   \n",
       "\n",
       "  comments_count  ...     trust      fear  negative   sadness     anger  \\\n",
       "0            109  ...  0.007296  0.003192  0.003648  0.002736  0.001824   \n",
       "1            205  ...  0.008208  0.004560  0.006840  0.002280  0.003648   \n",
       "2            234  ...  0.003648  0.001368  0.001824  0.001824  0.000912   \n",
       "3            236  ...  0.004104  0.002736  0.004560  0.002736  0.002736   \n",
       "4            542  ...  0.004104  0.000912  0.001824  0.001368  0.000912   \n",
       "\n",
       "   surprise  positive   disgust       joy anticipation  \n",
       "0  0.004560  0.019608  0.001368  0.010032     0.008664  \n",
       "1  0.002280  0.021888  0.002280  0.004560     0.008664  \n",
       "2  0.001824  0.005928  0.000000  0.002280     0.005016  \n",
       "3  0.001824  0.006840  0.002280  0.002736     0.002280  \n",
       "4  0.002280  0.008208  0.000456  0.003192     0.003192  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(df1, comment,  how='left', left_on='video_id', right_on = 'video_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2418 entries, 0 to 2417\n",
      "Data columns (total 34 columns):\n",
      "video_id                        2418 non-null object\n",
      "transcript                      2418 non-null object\n",
      "polarity_neg_transcript         2418 non-null float64\n",
      "polarity_pos_transcript         2418 non-null float64\n",
      "polarity_neu_transcript         2418 non-null float64\n",
      "polarity_compound_transcript    2418 non-null float64\n",
      "tags                            2408 non-null object\n",
      "title                           2408 non-null object\n",
      "publushed_date                  2408 non-null datetime64[ns]\n",
      "comments_count                  2394 non-null object\n",
      "dislike_count                   2408 non-null object\n",
      "like_count                      2408 non-null object\n",
      "views_count                     2408 non-null object\n",
      "today                           2408 non-null datetime64[ns]\n",
      "days_age                        2408 non-null float64\n",
      "views_per_day                   2408 non-null float64\n",
      "dislike_perc_of_likes           2408 non-null float64\n",
      "success                         2408 non-null object\n",
      "prime_tag                       2408 non-null object\n",
      "comments                        1978 non-null object\n",
      "polarity_neg_comments           1978 non-null float64\n",
      "polarity_pos_comments           1978 non-null float64\n",
      "polarity_neu_comments           1978 non-null float64\n",
      "polarity_compound_comments      1978 non-null float64\n",
      "trust                           1978 non-null float64\n",
      "fear                            1978 non-null float64\n",
      "negative                        1978 non-null float64\n",
      "sadness                         1978 non-null float64\n",
      "anger                           1978 non-null float64\n",
      "surprise                        1978 non-null float64\n",
      "positive                        1978 non-null float64\n",
      "disgust                         1978 non-null float64\n",
      "joy                             1978 non-null float64\n",
      "anticipation                    1978 non-null float64\n",
      "dtypes: datetime64[ns](2), float64(21), object(11)\n",
      "memory usage: 661.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('JOINT_ted_video_transcripts_comments_stats.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(df1, picklefile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
